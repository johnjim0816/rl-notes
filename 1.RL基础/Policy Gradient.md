## 1. Value-based方法的不足

诸如DQN之类的value-based方法主要存在以下问题：

* 无法处理连续动作[^1]
* 无法解决随机(Stochastic)策略问题：value-based方法通常学习的最优策略是确定性(Deterministic)策略

## 2. 策略梯度引入







































## 参考文献

[^1]: [Policy Gradient paper](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)